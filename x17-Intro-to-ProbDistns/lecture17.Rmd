---
title: "Lecture 17 - Introduction to Probability Distributions"
author: "Emily Josephs"
date: "October 31 2023"
output:
  ioslides_presentation:
    transition: 0.001
    bigger: true
    incremental: true
---
<!-- To render the lecture in Rmarkdown, enter the command below in the R console -->
<!-- rmarkdown::render("lecture17.Rmd") -->

```{r,echo=FALSE}
	#set any global options
	options(digits=3)
	set.seed(123)
```


```{r, eval=F, echo=F}
flips <- function(nFlips){
	flips <- sample(c('H','T'), nFlips, replace=TRUE)
	return(flips)
}

flips(3)

#mySims = replicate(100, flips(3), simplify=TRUE)
```

## Today: Probability distributions!

What if the probability of different outcomes varies?

How do we describe this situation?

## Motivating examples

Pick a random person in the room. What is the probability that they are 5'5"?


## Coin-flipping {.build}

Let's say I hand you a quarter and ask you to flip it 3 times 
and count the number of heads that you get.

- This is the **state space** (the list of all possible outcomes)
	+ {HHH, HHT, HTH, THH, TTH, THT, HTT, TTT}

- Some questions to answer in your teams:

1. What is the probability of the sequence THH?
2. What is the probability I get exactly 2 heads out of 3 flips?
3. What is the probabilty I **_do not_** get exactly 2 heads out of 3 flips?


## Coin-flipping: 3-flip state space {.build}

- First, let's define the **state space** (the list of all possible outcomes)
	+ {HHH, HHT, HTH, THH, TTH, THT, HTT, TTT}

1. What is the probability of the sequence THH?
	+ {HHH, HHT, HTH,<span style="color:red">THH</span>, TTH, THT, HTT, TTT} = 1/8
2. What is the probability I get exactly 2 heads out of 3 flips?
	+ {HHH,<span style="color:red">HHT</span>,<span style="color:red">HTH</span>,<span style="color:red">THH</span>, TTH, THT, HTT, TTT} = 3/8
3. What is the probabilty I _do not_ get exactly 2 heads out of 3 flips?
	+ {<span style="color:red">HHH</span>, HHT, HTH, THH,<span style="color:red">TTH</span>,<span style="color:red">THT</span>,<span style="color:red">HTT</span>,<span style="color:red">TTT</span>} = 1 - 3/8 = 5/8

## Coin-flipping: 4-flip state space {.build}

What about if I gave you 4 flips?  What's p(2 heads)?

HHHH, <span style="color:red">THHT</span>, HHTH, <span style="color:red">TTHH</span>, 
<span style="color:red">HTTH</span>, TTHT, <span style="color:red">HHTT</span>, TTTT, \
THHH, HHHT, <span style="color:red">THTH</span>, HTHH, 
TTTH, <span style="color:red">HTHT</span>, THTT, HTTT

p(2 heads) = 6/16 = 3/8
\
\
Clearly, writing out all possible outcomes and colorizing them using CSS notation in Rmarkdown and then counting them will get tedious.

We must generalize!

## Coin-flipping: 4-flip state space {.build}

state space = \
 
HHHH, THHT, HHTH, TTHH, 
HTTH, TTHT, HHTT, TTTT, \
THHH, HHHT, THTH, HTHH, 
TTTH, HTHT, THTT, HTTT


|     Heads    |  Probability  |
|:------------:|:-------------:|
|      0       |     1/16      |
|      1       |     4/16      |
|      2       |     6/16      |
|      3       |     4/16      |
|      4       |     1/16      |

## Coin-flipping: 4-flip state space

state space = \
 
HHHH, THHT, HHTH, TTHH, 
HTTH, TTHT, HHTT, TTTT, \
THHH, HHHT, THTH, HTHH, 
TTTH, HTHT, THTT, HTTT

\
\

This is a distribution of probabilities... \

Can we make a **probability distribution**?

## Probability distributions, random variables {.build}

A **_probability distribution_** is a function that provides 
the probability of each outcome in the sample space.

In doing so, it is implicitly treating the outcome of 
the process (in this case, coin-flipping) as a **_random variable_**.

A **_random variable_** is a variable whose value is the 
outcome of a **_stochastic_** (or random) **_process_**.

## Coin-flipping: a probability distribution {.build}

|     Heads    |  Probability  |
|:------------:|:-------------:|
|      0       |     1/16      |
|      1       |     4/16      |
|      2       |     6/16      |
|      3       |     4/16      |
|      4       |     1/16      |

\

<div class="centered">
$\ p(\text{1 head}) < p(\text{2 heads})$
</div>

## Coin-flipping: a probability distribution {.build}

<div class="centered">
$\ p(\text{1 head}) < p(\text{2 heads})$
</div>

\

but we know, out of 4 flips:

\

<div class="centered">
$\ p(\text{HTTT}) = p(\text{HTHT})$
</div>


\

so what's the deal?

## Coin-flipping: a probability distribution {.build}

<div class="centered">
$p(\text{1 head in 4 flips})$
</div>

HHHH, THHT, HHTH, TTHH, 
HTTH, <span style="color:red">TTHT</span>, HHTT, TTTT, \
THHH, HHHT, THTH, HTHH,
<span style="color:red">TTTH</span>, HTHT, <span style="color:red">THTT</span>, <span style="color:red">HTTT</span>

\

{
<span style="color:red">HTTT</span>,
<span style="color:red">THTT</span>,
<span style="color:red">TTHT</span>,
<span style="color:red">TTTH</span>
} = 4/16

## Coin-flipping: a probability distribution {.build}

<div class="centered">
$p(\text{2 heads in 4 flips})$
</div>

HHHH, <span style="color:red">THHT</span>, HHTH, <span style="color:red">TTHH</span>, 
<span style="color:red">HTTH</span>, TTHT, <span style="color:red">HHTT</span>, TTTT, \
THHH, HHHT, <span style="color:red">THTH</span>, HTHH, 
TTTH, <span style="color:red">HTHT</span>, THTT, HTTT

{
<span style="color:red">HHTT</span>,
<span style="color:red">HTHT</span>,
<span style="color:red">HTTH</span>,
<span style="color:red">THHT</span>
<span style="color:red">THTH</span>
<span style="color:red">TTHH</span>
} = 6/16

\

Because the coin is fair, each **shared event** (comprised of 4 simple events) is equi-probable.  

\

But, there are more _ways_ of realizing the complex event of **(2heads)**!

## Coin-flipping: a probability distribution {.build}

So, we know that our **_probability distribution function_** will have 
two components: 

1. The probability of each **shared event**
2. The number of shared events that give a desired outcome (**complex event**)

\

Let's generalize for more flips!

_n_ = number of trials \
_k_ = number of successes \
_p_ = probability of heads (assume 1/2) \

## Coin-flipping: a probability distribution {.build}


_n_ = number of flips \
_k_ = number of heads \
_p_ = probability of heads (assume 1/2) \

Two components to calculating the probability of _k_ successes: 

Part 1: what's the probability of the **shared event** comprised of a specific sequence of heads and tails??

<div class="centered">
$\Large (1/2)^{n}$
</div>

Part 2: how many permutations of _n_ events give _k_ heads?



## Coin-flipping: a probability distribution {.build}
### how many permutations of _n_ events give _k_ successes?

For four flips, we had the table below: 


|     Heads    |  Probability  |
|:------------:|:-------------:|
|      0       |     1/16      |
|      1       |     4/16      |
|      2       |     6/16      |
|      3       |     4/16      |
|      4       |     1/16      |


## Coin-flipping: a probability distribution

We can calculate for specific values of _n_ and _k_:
```{r,echo=FALSE,fig.height=5.5,fig.width=6.5}
plot(0:4,choose(4,0:4),pch=19,cex=1.5,
	xlab="k",ylab="permutations with k successes",
	main="n=4",ylim=c(0,7))
```

## Coin-flipping: a probability distribution

We can calculate for specific values of _n_ and _k_:
```{r,echo=FALSE,fig.height=5.5,fig.width=6.5}
plot(0:4,choose(4,0:4),pch=19,cex=1.5,xlim=c(0,6),
	xlab="k",ylab="permutations with k successes",ylim=c(0,25))
	points(0:5,choose(5,0:5),pch=19,cex=1.5,col=2)
	points(0:6,choose(6,0:6),pch=19,cex=1.5,col=3)
	legend(x="topright",col=c(1,2,3),pch=19,pt.cex=1.5,
			legend=c("n=4","n=5","n=6"))
```

## Coin-flipping: a probability distribution

We can calculate for specific values of _n_ and _k_:
```{r,echo=FALSE,fig.height=5.5,fig.width=6.5}
plot(0:4,choose(4,0:4),pch=19,cex=1.5,xlim=c(0,8),
	xlab="k",ylab="permutations with k successes",ylim=c(0,75))
	points(0:5,choose(5,0:5),pch=19,cex=1.5,col=2)
	points(0:6,choose(6,0:6),pch=19,cex=1.5,col=3)
	points(0:7,choose(7,0:7),pch=19,cex=1.5,col=4)
	points(0:8,choose(8,0:8),pch=19,cex=1.5,col=6)
	legend(x="topright",col=c(1,2,3,4,6),pch=19,pt.cex=1.5,
			legend=c("n=4","n=5","n=6","n=7","n=8"))
```

## Coin-flipping: a probability distribution
### how many permutations of _n_ events give _k_ successes?

Pascal's Triangle!

```{r, out.width="705px",out.height="328px",echo=FALSE,fig.align="center"}
	knitr::include_graphics("figs/pascals_triangle.png")
```

## Coin-flipping: a probability distribution

```{r, out.width="600px",echo=FALSE,fig.align="center"}
	knitr::include_graphics("figs/PascalTriangleAnimated2.gif")
```

## Not just Pascal's triangle
Khayyam's triangle (Persia, 1100s)

Yang Hui's triangle (China, 1200s)

Tartaglia's triangle (Italy, 1500s)

Pascal's triangle (France, 1600s)

## Yang Hui's triangle
```{r, out.width="300px",echo=FALSE,fig.align="center"}
	knitr::include_graphics("figs/Yanghui_triangle.gif")
```


## Coin-flipping: a probability distribution
### how many permutations of _n_ events give _k_ successes?

Binomial coefficient!

```{r, out.width="705px",out.height="328px",echo=FALSE,fig.align="center"}
	knitr::include_graphics("figs/pascals_triangle.png")
```

## Coin-flipping: a probability distribution
### how many permutations of _n_ events give _k_ successes?

\

<div class="centered">
$\Huge {{n}\choose{k}} = \frac{n!}{k!(n-k)!}$
</div>

\

<div class="centered">
$\large x! = x \times (x-1) \times (x-2) \times \dots \times 1$
</div>

## Coin-flipping: a probability distribution {.build}

_n_ = number of flips \
_k_ = number of heads
_p_ = probability of heads (assume 1/2) \

Two components to calculating the probability of _k_ successes: 

Part 1: what's the probability of each **shared event**

<div class="centered">
$\Large (1/2)^{n}$
</div>

Part 2: how many permutations give _k_ successes?

<div class="centered">
$\Large {{n}\choose{k}} = \frac{n!}{k!(n-k)!}$
</div>

## Coin-flipping: probability distribution function

_n_ trials, _k_ successes, 1/2 probability of success \

<div class="centered">
$\ {{n}\choose{k}}(1/2)^{n}$
</div>

\

Work in groups to write a function that returns 
the probability of a number of heads (_k_) given a probability of 
flipping heads of 1/2 and a number of flips (_n_).

Hint - check out the function `choose()`

Make a plot with 1 to 100 on the x axis, and the y axis shows your probability of x heads if you flip a coin 100 times.

## Coin-flipping: probability distribution function

_n_ trials, _k_ successes, 1/2 probability of success \


<div class="centered">
$\ {{n}\choose{k}}(1/2)^{n}$
</div>

\
```{r}
	coin.flip.prob <- function(n,k){
		prob <- choose(n,k) * (1/2)^n
		return(prob)
	}
```

## Coin-flipping: probability distribution function {.build}

```{r,fig.width=6.5,fig.height=5.5,fig.align="center",echo=TRUE, eval=F}
	par(oma=c(3,0,0,0))
	plot(coin.flip.prob(n=100,k=0:100),
			xlab="heads",ylab="probability",
			pch=20,col=adjustcolor(1,0.7))
```


## Coin-flipping: probability distribution function {.build}

```{r,fig.width=6.5,fig.height=5.5,fig.align="center",echo=FALSE}
	par(oma=c(3,0,0,0))
	plot(coin.flip.prob(n=100,k=0:100),
			xlab="heads",ylab="probability",
			pch=20,col=adjustcolor(1,0.7))
```

## Coin-flipping: probability distribution function {.build}
What if we change p?

If p(heads) = 0.1 and you flip a coin 3 times,

p(HHH) = ?\
p(TTT) = ?\
p(THH) = ?\

## Coin-flipping: probability distribution function {.build}
If p(heads) = 0.1 and you flip a coin 3 times,

p(HHH) = $(0.1)^{3}$ = 0.001\
p(TTT) = $(0.9)^{3}$ =0.729\
p(THH) = $(0.9)^{1} \times (0.1)^{2}$ = 0.009\   

## Generalizing for different values of p

_n_ = number of trials \
_k_ = number of successes \
_p_ = probability of success (for coin flips, assume 1/2) \

Two components to calculating the probability of _k_ successes: 

Part 1: what's the probability of the **shared event** comprised of _k_ successes and _n_-_k_ failures?

<div class="centered">
$\Large p^k \times (1-p)^{n-k}$
</div>

Part 2: 
<div class="centered">
$\ {{n}\choose{k}}$
</div>

## The binomial distribution!!!

<div class="centered">
$\Large {{n}\choose{k}} p^k \times (1-p)^{n-k}$

</div>

## Write a function!
Work in your teams to edit your function from before to account for variable values of p.

## Write a function

\
```{r}
	coin.flip.prob <- function(n,k,p){
		prob <- choose(n,k) * p^k * (1-p)^(n-k)
		return(prob)
	}
```


## {.build}

<div class="centered">
```{r binomial_animation,fig.show="animate",fig.width=6.5,fig.height=5.5,interval=0.5,cache=TRUE,echo=FALSE}
	for(i in 1:20){
		plot(1:100,coin.flip.prob(n=100,1:100,i/20),
			xlab="",ylab="probability",main="Probability of k successes over values of p",
			pch=20,col=adjustcolor(1,0.7),ylim=c(0,0.16)) ; 
		TeachingDemos::subplot(fun = {
						plot(0,xlim=c(0,1),ylim=c(0,1),xlab="",ylab="",main="",type='n',xaxt='n',yaxt='n')
							mtext(side=3,text="value of p",font=2)
							axis(side=1,at=c(0,0.5,1),labels=c(0,0.5,1))
							axis(side=2,at=c(0,0.5,1),labels=c(0,0.5,1))
							abline(0,1,col=2)
							points(i/20,i/20)
						},
						x=c(35,65),y=c(0.11,0.15))
	}
```
</div>

## Recap

1. The outcome of a random process is called a **_random variable_**

2. To calculate the probability of any given value of the random variable:
	+ we can either define the state space and count or
	+ we can figure out the probability distribution function

3. A **_probability distribution function_** is a rule or formula 
that describes the probability of all possible outcomes of a random event

4. The **_binomial distribution_** describes the probabilities of success in a set of trials.


## The Binomial Distribution {.build}

Given:

 - a number of trials (**_n_**)
 
 - and a probability of success (**_p_**)

can we come up with a rule for calculating 
the probability of any number of successes (**_k_**)?

\

E.g., what's the probability of 43 successes out of 100 trials?

## The binomial distribution {.build}

What's the probability of 43 successes out of 100 trials?

$P(A \cap B) = P(A) \times P(B)$

$P(43 ~\text{successes}) = P(\text{success})^{43} \times P(\text{failure})^{100-43}$


## The binomial distribution {.build}

What is the probability of any _particular_ sequence of **_n_** trials 
that contains **_k_** successes?

the probability of each success is ______


## The binomial distribution 

What is the probability of any _particular_ sequence of **_n_** trials 
that contains **_k_** successes?

the probability of each success is $p$

## The binomial distribution 

What is the probability of any _particular_ sequence of **_n_** trials 
that contains **_k_** successes?

the probability of each success is $p$

so the probability of $k$ successes is ______


## The binomial distribution 

What is the probability of any _particular_ sequence of **_n_** trials 
that contains **_k_** successes?

the probability of each success is $p$

so the probability of $k$ successes is $p^{k}$

## The binomial distribution 

What is the probability of any _particular_ sequence of **_n_** trials 
that contains **_k_** successes?

the probability of each success is $p$

so the probability of $k$ successes is $p^{k}$

the probability of each fail is ______

## The binomial distribution 

What is the probability of any _particular_ sequence of **_n_** trials 
that contains **_k_** successes?

the probability of each success is $p$

so the probability of $k$ successes is $p^{k}$

the probability of each fail is $1-p$

## The binomial distribution 

What is the probability of any _particular_ sequence of **_n_** trials 
that contains **_k_** successes?

the probability of each success is $p$

so the probability of $k$ successes is $p^{k}$

the probability of each fail is $1-p$

if there are $n$ trials and $k$ successes, there are ____ fails

## The binomial distribution 

What is the probability of any _particular_ sequence of **_n_** trials 
that contains **_k_** successes?

the probability of each success is $p$

so the probability of $k$ successes is $p^{k}$

the probability of each fail is $1-p$

if there are $n$ trials and $k$ successes, there are $n-k$ fails

## The binomial distribution 

What is the probability of any _particular_ sequence of **_n_** trials 
that contains **_k_** successes?

the probability of each success is $p$

so the probability of $k$ successes is $p^{k}$

the probability of each fail is $1-p$

if there are $n$ trials and $k$ successes, there are $n-k$ fails

so the probability of all the fails is _____

## The binomial distribution 

What is the probability of any _particular_ sequence of **_n_** trials 
that contains **_k_** successes?

the probability of each success is $p$

so the probability of $k$ successes is $p^{k}$

the probability of each fail is $1-p$

if there are $n$ trials and $k$ successes, there are $n-k$ fails

so the probability of all the fails is $(1-p)^{n-k}$

## The binomial distribution 

What is the probability of any _particular_ sequence of **_n_** trials 
that contains **_k_** successes?

the probability of each success is $p$

so the probability of $k$ successes is $p^{k}$

the probability of each fail is $1-p$

if there are $n$ trials and $k$ successes, there are $n-k$ fails

so the probability of all the fails is $(1-p)^{n-k}$

and the probability of a particular sequence of **_n_** trials containing **_k_** successes is ______


## The binomial distribution

What is the probability of any _particular_ sequence of **_n_** trials 
that contains **_k_** successes?

the probability of each success is $p$
 
so the probability of $k$ successes is $p^k$
 
the probability of each fail is $1-p$
 
if there are $n$ trials and $k$ successes, there are $n-k$ fails
 
so the probability of all fails is $(1-p)^{(n-k)}$
 
and the probability of a particular sequence of **_n_** trials containing **_k_** successes is $p^k \times (1-p)^{(n-k)}$


## The binomial distribution  {.build}

The probability of a particular sequence of **_n_** trials containing **_k_** successes is $p^k \times (1-p)^{(n-k)}$

Now we need to know _how many ways there are_ of getting a sequence of 
**_n=100_** trials containing **_k=43_** successes.

<div class="centered">
$\Large {{n}\choose{k}}$
</div>

```{r,eval=TRUE}
	choose(n=100,k=43)
```


## The Binomial distribution  {.build}

Well, we've just derived the **_probability distribution function_**.

<div class="centered">
$\Large {{n}\choose{k}} \times \left( p^k \times (1-p)^{n-k}	\right)$
</div>

## The Binomial distribution  {.build}

Why are we multiplying the two terms together?

Imagine that we have 2 flips and we want to know how likely we are to get 1 heads?

Our state space = $[H,H], [H,T], [T,H], [T,T]$

All of these options are equiprobable!

$P(2~\text{heads}) = P([H,T]) + P([T,H])$

$P(2~\text{heads}) = 2 \times P([H,T])$

```{r}
choose(n=2, k=1)
```


## The Binomial distribution  {.build}


```{r, echo=T}
	coin.flip.prob <- function(n,k,p){
		prob <- choose(n,k) * p^k * (1-p)^(n-k)
		return(prob)
	}
```
	
```{r, echo=T}
	coin.flip.prob(n=100,k=43,p=0.5)
```

## Coin-flipping {.build}
```{r,fig.width=6.5,fig.height=5,fig.align="center",echo=T}
	plot(coin.flip.prob(n=100,k=0:100,p=0.5),
			xlab="successes",ylab="probability")
```

## Coin-flipping {.build}
```{r,fig.width=6.5,fig.height=5,fig.align="center",echo=T}
	plot(coin.flip.prob(n=100,k=0:100,p=0.3),
			xlab="successes",ylab="probability")
```


## 
```{r,fig.width=6.5,fig.height=5,fig.align="center",echo=FALSE}
	plot(0,type='n',xlim=c(0,25),ylim=c(0,0.2),
			xlab="successes",ylab="probability",main="")
		lines(0:25,coin.flip.prob(n=25,k=0:25,p=0.3),lwd=3,col="blue")
		lines(0:25,coin.flip.prob(n=25,k=0:25,p=0.5),lwd=3,col="purple")
		lines(0:25,coin.flip.prob(n=25,k=0:25,p=0.7),lwd=3,col="red")
		legend(x="topright",lty=1,lwd=3,col=c("blue","purple","red"),legend=c(0.3,0.5,0.7),title="p(heads) = ")
```


## A reminder about simulations {.build}

We have talked about two tools for understanding probability: simulations and analytical solutions.

Analytical solutions involve directly calculating probabilities.

Simulations involve using tools like sample() to mimic the process creating probabilities.

Simulations can be different every time you run them.

## A reminder about simulations

```{r, out.width="500px",echo=FALSE,fig.align="center"}
	knitr::include_graphics("../x15-Intro-to-Probability/figs/sims.jpg")
```


## Probability distributions: the binomial {.build}

If a random variable **_X_** is binomially distributed, we write:

\

<div class="centered">
$\Large X \sim B(n,p)$
</div> 


Read as: "_X_ is a draw from a binomial distribution 
with parameters _n_ and _p_"


And, if **_X_** is a draw from a binomial distribution, 
we can use the **_binomial probability distribution function_** 
to calculate the probability for any value of **_X_ = k**, given **_n_** and **_p_**.

## Probability distributions: the binomial {.build}

There are also tools available for working with the binomial distribution:

```{r,eval=FALSE}
# look at rbinom and dbinom
?rbinom
```

Using `rbinom`, generate 1 sample of 100 draws from a 
binomial distribution with `p=0.6`.

```{r}
rbinom(n=1,size=100,p=0.6)
rbinom(n=1,size=100,p=0.6)
```

## Team exercise
Use `rbinom` to sample 1000 draws from the binomial distribution. Pick your own value of *p*.

Plot the histogram of the values that you get.

Calculate the mean of the values.

Calculate the variance of the values (hint: use `var()`).

## Probability distributions: the binomial {.build}

The mean and variance of the binomial distribution are 
defined!

If $X \sim B(n,p)$, we know:

<div class="centered">
$\Large \mathbb{E}[X] = np$
</div> 

and

<div class="centered">
$\Large \mathbb{V}ar(X) = np(1-p)$
</div>

Check to make sure that your estimates from the teams match these values.

## Wait what's a variance? {.build}

The variance tells you about the amount of spread in the data.

$\large \mathbb{V}ar(X) = \mathbb{E}(x_{i}-\bar{x})^{2}$

The variance will be higher if things tend to be farther away from the mean.

(hint: Wikipedia is your friend for math concepts like variance)

## Probability distributions {.build}

The binomial is only one probability distribution; 
there are many others!

Why are they useful?

Because they describe processes that shape 
the world around us!

## Distributions and Random Variables {.build}

Random variables come in two flavors: **_discrete_** and **_continuous_**

- **Discrete** random variables are things that can be counted
	+ heads in a coinflip experiment, fish in a lake, flowers on a plant
\
\

- **Continuous** random variables are things that can be measured
	+ height or weight

\
\

## Distributions and Random Variables {.build}

Discrete probability distributions have 
**_probability mass functions_**

- <div class="centered">
$\Large {{n}\choose{k}}p^k (1-p)^{n-k}$
</div>

- a **_pmf_** gives the probability that a discrete random variable is _exactly_ equal to some value
	+ e.g., what's the probability of getting _exactly_ 43 heads out of 100 coin flips
\

What about continuous RVs?

## {.columns-2 .build}
### Discrete (heads):

\
\

```{r,fig.width=4,fig.height=4,echo=FALSE,align="center"}
plot(coin.flip.prob(n=100,k=0:100,p=0.5),
			xlab="successes",ylab="probability",
			pch=20,col=adjustcolor(1,0.7),main="discrete")
```

\
\

### Continuous (height):

\
\

```{r,fig.width=4,fig.height=4,echo=FALSE,align="center"}
norm.prob <- function(x,mean,sigma){
 	prob <- exp(-((x-mean)^2/(2*sigma^2)))/sqrt(2*pi*sigma^2)
 	return(prob)
}
lower <- 10
upper <- 130
plot(lower:upper,norm.prob(lower:upper,mean=70,sigma=20),type='n',
		xlab="height",ylab="probability",main="continuous")
	lines(seq(lower,upper,length.out=500),
			norm.prob(seq(lower,upper,length.out=500),mean=70,sigma=20))
```

## Probability density functions {.build}

A continuous variable can take 
an infinite possible number of values, 
**the probability of any specific value is 0**.
 
So, a pdf measures the _relative_ probability 
of a given value.

<div class="centered">
```{r,fig.width=5,fig.height=4,echo=FALSE,align="center"}
norm.prob <- function(x,mean,sigma){
 	prob <- exp(-((x-mean)^2/(2*sigma^2)))/sqrt(2*pi*sigma^2)
 	return(prob)
}
lower <- 10
upper <- 130
plot(lower:upper,norm.prob(lower:upper,mean=70,sigma=20),type='n',
		xlab="height",ylab="probability",main="continuous")
	lines(seq(lower,upper,length.out=500),
			norm.prob(seq(lower,upper,length.out=500),mean=70,sigma=20))
```
</div>

## Intro to random variables: recap

1. The outcome of a random process is called a **_random variable_**

2. To calculate the probability of any given value of the random variable:
	+ we can either define the state space and count or
	+ we can figure out the probability distribution function

3. A **_probability distribution function_** is a rule or formula 
that describes the probability of all possible outcomes of a random event

## Intro to probability distributions: recap 

1. There are many named **_probability distributions_**. These are useful 
for describing different natural processes.

2. There are many tools for working with different probability distributions, 
including tools for simulating data, and calculations for the expected mean and variance

3. Probability distributions can be either discrete or continuous.
	+ the probability of discrete events can be characterized by a **_probability mass function_**
	+ the probability of any value in a continuous distribution is 0, but the _relative_ probability 
	can be described by a **_probability density function_**

## Get to know a distribution!

**continuous**: beta, exponential, gamma, lognormal, normal, uniform

**discrete**: poisson, geometric, negative binomial

## Shiny demo!!

## Get to know a distribution!

Make presentation on google slides, including:

1. A brief history of the distribution (wikipedia is your friend, citations unnecessary)
2. A walkthrough of the notation, with an explanation of all parameters
3. Description of mean and variance, with some intuition-(and character!)-building discussion
4. State the bounds of the distribution (if there are any), and state whether it is continuous or discrete
5. Examples of data that are well described by the distribution (preferably biological, better if it's from your field)
6. Shiny demo (In a separate Rmarkdown file)