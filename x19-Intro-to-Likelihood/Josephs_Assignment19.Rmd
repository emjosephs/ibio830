---
title: "Intro to Likelihood: Assignment"
output:
  html_document: default
language: R
---

<!-- To render the assignment in Rmarkdown, enter the command below in the R console -->
<!-- rmarkdown::render("Class_19_Assignment.Rmd") -->

#### Due by midnight before the beginning of next class (11/10)

Save this Rmarkdown script as a file named “YourlastName_Assignment19.Rmd”. 
For each question, fill out the answer and, where requested, 
provide the relevant R code using "```" and the echo = TRUE argument.

When finished, Knit your script together into an html report, 
saved as “YourlastName_Assignment19.html” and upload the 
resulting file to the D2L site (in today’s class folder) to turn it in. 
It is due before our next class.

\

**This homework assignment will test your abilities to:**

1. think critically and creatively about probability distributions

2. extrapolate from in-class exercises to apply likelihood-based inference to arbitrary distributions

3. use your R skillz: function building, data visualization, etc.

\

### Question 1

What is the log product rule, and how/why is it used for likelihood-based inference?

The log product rule is that log(A x B) = log(A) + log(B). 
It's important for likelihood-based inference because it allows you to calculate the likelihood of multiple events without breaking your computer with small numbers


### Question 2

Everything from class used the binomial distribution, so let's try using the Poisson distribution instead.
\
\
\
a) If $X \sim \text{Pois}(\lambda)$, calculate $P(2 | \lambda=4)$
\
```{r, echo=T}
myProb = dpois(x=2, lambda=4)
myProb
```

b) You make 2 draws from the Poisson distribution and get 2 the first time, and 3 the second time. What is the probability of this outcome of $\lambda$ is 4?

```{r, echo=T}
myProb2 = prod(sapply(c(2,3), function(x){dpois(x, lambda=4)}))
myProb2
```

c) What is the log-likelihood of the outcome from part b?
```{r, echo=T}
myLogLike = sum(sapply(c(2,3), function(x){dpois(x, lambda=4, log=T)}))
myLogLike
```



### Question 3

Use maximum likelihood inference to estimate 
the parameter values I used to simulate data from a Poisson distribution, 
which are saved as a .Robj file in the Class 19 folder.
You should refer to the lecture .Rmd file for helpful reference 
code that you can cannibalize.
Your answers from Question 2 will also be helpful.

I've included pseudocode below to help you on your journey, but you don't need to use it.

```{r, eval=T}
################
#	load in simulated dataset 
#	hint: see the function load()
#		don't forget to specify full file paths and use quotes
################

setwd('~/Documents/ibio830/x19-Intro-to-Likelihood/') ## replace this with your own directory
load('poisson_data.Robj')

################
# visualize data
#	hint: hist() is always a friend
################
hist(poisson.data)

################
# get MLE:
################

# don't forget that the probability of a shared event 
#	should be calculated as the sum of the logs of the 
#	simple events that make up the shared event
#

## pick a set of lambdas based on the histogram
lambdas <- seq(0,8,length.out=1000)


## write a function to calculate the log-likelihood of the data for a given lambda
myLogLikeF = function(l){sum(sapply(poisson.data, function(x){dpois(x, lambda=l, log=T)}))}
  
# run your function on all the lambdas in your set
myLogLikes <- sapply(lambdas, myLogLikeF)

# ML estimate for lambda is:
myMLE <- lambdas[which.max(myLogLikes)]
myMLE

## plot your data to see if it looks right
plot(lambdas,myLogLikes, xlab = "lambda",bty="n", ylab = "log likelihood")
abline(v = myMLE, col="red", lwd=2)


```